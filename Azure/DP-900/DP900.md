# Azure Data Fundamentals DP-900

## Learning Path 1: Explore Core Data Concepts

Data is the foundation on which all software is built.

### Module 1: Explore core data concepts

Data powers the digital transformation that is sweeping across organizations and society in general.

### Unit 1: Identify data formats

Data is a collection of facts such as numbers, descriptions, and observations used to record information. Data structures in which this data is organized often represents entities that are important to an organization (such as customers, products, sales orders, and so on).

1. Structured data: Structured data is data that adheres to a fixed schema, so all of the data has the same fields or properties. Structured data is often stored in a database in which multiple tables can reference one another by using key values in a relational model.
    - Relational database
2. Semi-structured data: Semi-structured data is information that has some structure, but which allows for some variation between entity instances.
3. Unstructured data: Unstructured data is data that has no identifiable structure, or is not organized in a pre-defined manner.

### Unit 2: Explore file storage

The specific file format used to store data depends on a number of factors, including:

1. The type of data being stored (structured, semi-structured, or unstructured).
2. The applications and services that will need to read, write, and process the data.
3. The need for the data files to be readable by humans, or optimized for efficient storage and processing.

Some common file formats are discussed below.

1. Delimited text files: Delimited text is a good choice for structured data that needs to be accessed by a wide range of applications and services in a human-readable format.Each field in the entity is separated by a delimiter character such as a comma or tab.
    - CSV
    - TSV
2. JavaScript Object Notation (JSON): JSON is a ubiquitous format in which a hierarchical document schema is used to define data entities (objects) that have multiple attributes.
3. Extensible Markup Language (XML): XML is a markup language that uses a hierarchical document schema to define data entities that have multiple attributes.
4. Binary Large Object (BLOB): BLOB is a binary file format that is optimized for efficient storage and processing of large binary objects.
    - Images
    - Videos
    - Audio

While human-readable formats for structured and semi-structured data can be useful, they're typically not optimized for storage space or processing.

Some common optimized file formats you might see include Avro, ORC, and Parquet:

1. Avro: Avro is a file format that contains a header defining the schema for the data in the file, and the data itself is stored in a binary format that is optimized for efficient storage and processing. It's a good choice for semi-structured data that needs to be stored in a compact format.
2. Optimized Row Columnar (ORC): ORC is a type of columnar store where the values in each column of a table are stored together. This makes it possible to read the values in a single column without having to read the entire row. ORC is a good choice for structured data that needs to be stored in a compact format.
3. Parquet: Parquet is another columnar storage format that is optimized for efficient storage and processing of large amounts of data. It's designed to work well with complex data structures and is a good choice for analytics workloads.

### Unit 3: Explore databases

A database is used to define a central system in which data can be stored and queried.

1. Relational database: A relational database is a database in which data is organized into tables that are related by common fields. Relational databases are often used to store structured data.

2. Non-relational database: A non-relational database is a database in which data is not organized in tables. Non-relational databases are often used to store semi-structured and unstructured data.
    - Key-value store: Data is stored as a collection of key-value pairs. Each key is associated with a single value in the collection. Key-value stores are often used to store semi-structured data.
    - Document store: Data is stored as a collection of documents. Each document contains a set of key-value pairs that define the attributes of the document. Document stores are often used to store semi-structured data.
    - Columnar store: Data is stored in columns rather than rows. This makes it possible to read the values in a single column without having to read the entire row. Columnar stores are often used to store structured data.
    - Graph store: Data is stored as a collection of nodes and edges. Nodes are the entities in the graph, and edges define the relationships between the nodes. Graph stores are often used to store semi-structured data.

### Unit 4: Explore transactional data processing

A transactional data processing system is what most people consider the primary function of business computing. Think of a transaction as a small, discrete, unit of work. The work performed by transactional systems is often referred to as Online Transactional Processing (OLTP).

To accomplish this, OLTP systems enforce transactions that support so-called ACID semantics:

1. Atomicity: All of the operations in a transaction must be completed successfully, or none of them are applied.
2. Consistency: The data must be in a consistent state when the transaction begins and when it ends.
3. Isolation: The data used in the transaction cannot be used by another transaction until the first transaction is complete.
4. Durability: The data must be committed to durable storage before the transaction is considered to be complete.

OLTP systems are typically used to support live applications that process business data - often referred to as line of business (LOB) applications.

### Unit 5: Explore analytical data processing

Analytical data processing typically uses read-only (or read-mostly) systems that store vast volumes of historical data or business metrics. Analytics can be based on a snapshot of the data at a given point in time, or a series of snapshots.

The specific details for an analytical processing system can vary between solutions, but a common architecture for enterprise-scale analytics looks like this:

1. Data files may be stored in a central data lake for analysis.
2. An extract, transform, and load (ETL) process copies data from files and OLTP databases into a data warehouse that is optimized for read activity.
3. Data in the data warehouse may be aggregated and loaded into an online analytical processing (OLAP) model, or cube.
4. The data in the data lake, data warehouse, and analytical model can be queried to produce reports, visualizations, and dashboards.
    - Data lake: A data lake is a central repository that contains a vast amount of raw, unprocessed data in its native format. Data lakes are often used to store semi-structured and unstructured data.
    - Data warehouse: A data warehouse is a central repository that contains data from multiple sources. Data warehouses are often used to store structured data.

An OLAP model is an aggregated type of data storage that is optimized for analytical workloads. Because OLAP data is pre-aggregated, queries to return the summaries it contains can be run quickly.

### Module 2: Explore data roles and services

Data professionals perform distinct roles in building and managing software solutions, and work with multiple technologies and services to do so.

## Learning Path 2: Explore relational data in Azure

## Learning Path 3: Explore non-relational data in Azure

## Learning Path 4: Explore data analytics in Azure